# üéµ Strengthen Music Recognition Feature

## Problems Identified

1. ‚ùå **Music cuts out** when recognition starts
2. ‚ùå **Bluetooth audio disconnects** and reconnects
3. ‚ùå **Phone switches audio routing** from speakers to mic
4. ‚ùå **Recognition fails** due to audio interruption

## Root Causes

### Issue 1: Audio Focus Conflict
When you request microphone access, Android pauses other audio by default.

### Issue 2: Audio Routing Change
System switches from output (Bluetooth/speaker) to input (microphone).

### Issue 3: ACRCloud/AudD Timeout
Recognition APIs have short timeouts (5-10 seconds).

---

## ‚úÖ Solutions

### Solution 1: Use System Audio Capture (Android 10+)

Instead of microphone, capture what's already playing:

```typescript
// Capacitor Plugin for Audio Capture
import { MediaProjection } from '@capacitor-community/media-projection';

async function captureSystemAudio() {
  try {
    // Request permission to capture screen/audio
    await MediaProjection.requestPermission();
    
    // Start capturing internal audio (not microphone)
    const audioStream = await MediaProjection.startCapture({
      captureAudio: true,
      captureVideo: false
    });
    
    // Record 10 seconds of system audio
    const audioBlob = await recordStream(audioStream, 10000);
    
    // Send to recognition API
    const result = await recognizeSong(audioBlob);
    
    return result;
  } catch (error) {
    console.error('System audio capture failed:', error);
    // Fallback to microphone
    return captureMicrophoneAudio();
  }
}
```

**Install plugin:**
```bash
npm install @capacitor-community/media-projection
npx cap sync android
```

**Add to AndroidManifest.xml:**
```xml
<uses-permission android:name="android.permission.RECORD_AUDIO" />
<uses-permission android:name="android.permission.FOREGROUND_SERVICE" />
```

---

### Solution 2: Audio Focus Management

Prevent music from pausing when capturing:

```typescript
// Native Android code (create a Capacitor plugin)
// android/app/src/main/java/AudioCapturePlugin.java

import android.media.AudioManager;
import android.media.AudioFocusRequest;

public class AudioCapturePlugin {
    
    public void requestAudioFocusForRecording() {
        AudioManager audioManager = (AudioManager) context.getSystemService(Context.AUDIO_SERVICE);
        
        // Request audio focus WITHOUT pausing other audio
        AudioFocusRequest focusRequest = new AudioFocusRequest.Builder(AudioManager.AUDIOFOCUS_GAIN_TRANSIENT_MAY_DUCK)
            .setAudioAttributes(
                new AudioAttributes.Builder()
                    .setUsage(AudioAttributes.USAGE_MEDIA)
                    .setContentType(AudioAttributes.CONTENT_TYPE_MUSIC)
                    .build()
            )
            .setAcceptsDelayedFocusGain(true)
            .setWillPauseWhenDucked(false)  // Don't pause other audio
            .setOnAudioFocusChangeListener(focusChange -> {
                // Handle focus changes
            })
            .build();
        
        audioManager.requestAudioFocus(focusRequest);
    }
}
```

---

### Solution 3: Background Recording Service

Create a foreground service that captures audio without interrupting playback:

```typescript
// Create Capacitor plugin
// RecognitionService.ts

import { registerPlugin } from '@capacitor/core';

export interface RecognitionServicePlugin {
  startRecognition(): Promise<{ success: boolean }>;
  stopRecognition(): Promise<void>;
  getResult(): Promise<{ songId: string; title: string; artist: string }>;
}

const RecognitionService = registerPlugin<RecognitionServicePlugin>('RecognitionService');

export default RecognitionService;
```

**Native implementation:**

```java
// android/app/src/main/java/RecognitionService.java

public class RecognitionService extends Service {
    
    @Override
    public int onStartCommand(Intent intent, int flags, int startId) {
        // Create notification for foreground service
        createNotificationChannel();
        Notification notification = new NotificationCompat.Builder(this, CHANNEL_ID)
            .setContentTitle("Listening to music...")
            .setContentText("Identifying song")
            .setSmallIcon(R.drawable.ic_music_note)
            .build();
        
        startForeground(1, notification);
        
        // Start audio capture in background
        new Thread(() -> {
            try {
                // Record audio for 10 seconds
                byte[] audioData = recordAudio(10000);
                
                // Send to recognition API
                RecognitionResult result = recognizeSong(audioData);
                
                // Broadcast result
                Intent resultIntent = new Intent("RECOGNITION_COMPLETE");
                resultIntent.putExtra("result", result);
                sendBroadcast(resultIntent);
            } catch (Exception e) {
                Log.e("RecognitionService", "Error", e);
            } finally {
                stopSelf();
            }
        }).start();
        
        return START_NOT_STICKY;
    }
    
    private byte[] recordAudio(int durationMs) {
        AudioRecord recorder = new AudioRecord(
            MediaRecorder.AudioSource.DEFAULT,  // Use DEFAULT instead of MIC
            44100,
            AudioFormat.CHANNEL_IN_MONO,
            AudioFormat.ENCODING_PCM_16BIT,
            8192
        );
        
        recorder.startRecording();
        
        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
        byte[] buffer = new byte[8192];
        
        long startTime = System.currentTimeMillis();
        while (System.currentTimeMillis() - startTime < durationMs) {
            int read = recorder.read(buffer, 0, buffer.length);
            if (read > 0) {
                outputStream.write(buffer, 0, read);
            }
        }
        
        recorder.stop();
        recorder.release();
        
        return outputStream.toByteArray();
    }
}
```

---

### Solution 4: Shazam-Style Quick Recognition

Use shorter capture duration with better quality:

```typescript
async function quickRecognize() {
  try {
    // Show loading immediately
    setRecognizing(true);
    
    // Capture only 3-5 seconds (faster, less disruptive)
    const audioBlob = await captureAudio({
      duration: 3000,  // 3 seconds
      sampleRate: 44100,
      quality: 'high',
      source: 'default'  // Uses best available source
    });
    
    // Send to recognition API with timeout
    const controller = new AbortController();
    const timeout = setTimeout(() => controller.abort(), 10000);
    
    const result = await fetch('https://api.audd.io/', {
      method: 'POST',
      body: createFormData(audioBlob),
      signal: controller.signal
    });
    
    clearTimeout(timeout);
    
    return await result.json();
  } catch (error) {
    if (error.name === 'AbortError') {
      throw new Error('Recognition timed out. Please try again.');
    }
    throw error;
  } finally {
    setRecognizing(false);
  }
}
```

---

### Solution 5: Multiple Recognition Sources

Try different audio sources in order of preference:

```typescript
async function recognizeWithFallback() {
  const sources = [
    'system',      // Android 10+ internal audio
    'default',     // Best available
    'microphone',  // Last resort
  ];
  
  for (const source of sources) {
    try {
      console.log(`[Recognition] Trying source: ${source}`);
      
      const audioBlob = await captureAudio({
        source,
        duration: 5000,
        sampleRate: 44100
      });
      
      const result = await recognizeSong(audioBlob);
      
      if (result.success) {
        console.log(`[Recognition] Success with source: ${source}`);
        return result;
      }
    } catch (error) {
      console.warn(`[Recognition] Failed with source: ${source}`, error);
      continue;
    }
  }
  
  throw new Error('Recognition failed with all sources');
}
```

---

### Solution 6: Prevent Bluetooth Disconnect

```typescript
// Before starting recognition
async function prepareAudioRouting() {
  if (Capacitor.getPlatform() === 'android') {
    // Keep Bluetooth connected
    await BluetoothAudio.setAudioMode({
      mode: 'NORMAL',  // Don't switch to COMMUNICATION mode
      bluetoothSco: false  // Don't use Bluetooth SCO (call mode)
    });
    
    // Request audio without affecting routing
    const stream = await navigator.mediaDevices.getUserMedia({
      audio: {
        echoCancellation: false,
        noiseSuppression: false,
        autoGainControl: false
      }
    });
    
    return stream;
  }
}
```

---

### Solution 7: Improve Recognition API Integration

**Use ACRCloud (Better than AudD):**

```typescript
import crypto from 'crypto';

async function recognizeWithACRCloud(audioBlob: Blob) {
  const accessKey = process.env.ACRCLOUD_ACCESS_KEY;
  const accessSecret = process.env.ACRCLOUD_ACCESS_SECRET;
  const host = 'identify-us-west-2.acrcloud.com';
  
  // ACRCloud requires specific format
  const timestamp = Math.floor(Date.now() / 1000);
  const signature = crypto
    .createHmac('sha1', accessSecret)
    .update(`POST\n/v1/identify\n${accessKey}\naudio\n1\n${timestamp}`)
    .digest('base64');
  
  const formData = new FormData();
  formData.append('sample', audioBlob, 'sample.wav');
  formData.append('access_key', accessKey);
  formData.append('data_type', 'audio');
  formData.append('signature_version', '1');
  formData.append('signature', signature);
  formData.append('sample_bytes', audioBlob.size.toString());
  formData.append('timestamp', timestamp.toString());
  
  const response = await fetch(`https://${host}/v1/identify`, {
    method: 'POST',
    body: formData
  });
  
  return await response.json();
}
```

**Or use Shazam API (via RapidAPI):**

```typescript
async function recognizeWithShazam(audioBlob: Blob) {
  // Convert to base64
  const base64Audio = await blobToBase64(audioBlob);
  
  const response = await fetch('https://shazam.p.rapidapi.com/songs/detect', {
    method: 'POST',
    headers: {
      'content-type': 'text/plain',
      'X-RapidAPI-Key': process.env.RAPIDAPI_KEY,
      'X-RapidAPI-Host': 'shazam.p.rapidapi.com'
    },
    body: base64Audio
  });
  
  return await response.json();
}
```

---

### Solution 8: User Experience Improvements

```tsx
// Better recognition UI
export function RecognitionButton() {
  const [isRecognizing, setIsRecognizing] = useState(false);
  const [progress, setProgress] = useState(0);
  
  const handleRecognize = async () => {
    try {
      setIsRecognizing(true);
      setProgress(0);
      
      // Show progress
      const progressInterval = setInterval(() => {
        setProgress(prev => Math.min(prev + 10, 90));
      }, 300);
      
      // Warn user
      toast({
        title: "Listening...",
        description: "Keep music playing for best results",
        duration: 3000
      });
      
      // Capture and recognize
      const result = await recognizeWithFallback();
      
      clearInterval(progressInterval);
      setProgress(100);
      
      // Navigate to song
      if (result.songId) {
        router.push(`/song/${result.songId}`);
      }
    } catch (error) {
      toast({
        title: "Recognition Failed",
        description: error.message || "Could not identify song. Try playing it louder.",
        variant: "destructive"
      });
    } finally {
      setIsRecognizing(false);
      setProgress(0);
    }
  };
  
  return (
    <Button
      size="lg"
      onClick={handleRecognize}
      disabled={isRecognizing}
      className="relative overflow-hidden"
    >
      {isRecognizing ? (
        <>
          <Loader2 className="h-5 w-5 animate-spin mr-2" />
          Listening... {progress}%
          
          {/* Progress bar */}
          <div 
            className="absolute bottom-0 left-0 h-1 bg-primary-foreground/30"
            style={{ width: `${progress}%` }}
          />
        </>
      ) : (
        <>
          <Mic className="h-5 w-5 mr-2" />
          Tap to Recognize
        </>
      )}
    </Button>
  );
}
```

---

### Solution 9: Offline Recognition (Advanced)

For local recognition without API calls:

```typescript
// Use TensorFlow.js for audio fingerprinting
import * as tf from '@tensorflow/tfjs';

async function localRecognition(audioBuffer: AudioBuffer) {
  // Extract audio features
  const features = extractMelSpectrogram(audioBuffer);
  
  // Load pre-trained model
  const model = await tf.loadLayersModel('/models/music-recognition/model.json');
  
  // Predict
  const prediction = model.predict(features);
  
  // Match against local database
  const songId = findClosestMatch(prediction);
  
  return songId;
}
```

---

## üéØ Recommended Implementation Order

### Phase 1: Quick Wins (Week 1)
1. ‚úÖ Shorter capture duration (5s ‚Üí 3s)
2. ‚úÖ Better error messages
3. ‚úÖ Progress indicator
4. ‚úÖ Add retry logic

### Phase 2: Audio Improvements (Week 2)
1. ‚úÖ Audio focus management
2. ‚úÖ Multiple source fallback
3. ‚úÖ Bluetooth preservation

### Phase 3: Advanced Features (Week 3-4)
1. ‚úÖ System audio capture (Android 10+)
2. ‚úÖ Background recognition service
3. ‚úÖ ACRCloud integration
4. ‚úÖ Offline recognition (optional)

---

## üì± Mobile-Specific Optimizations

### Android Permissions

```xml
<!-- AndroidManifest.xml -->
<uses-permission android:name="android.permission.RECORD_AUDIO" />
<uses-permission android:name="android.permission.FOREGROUND_SERVICE" />
<uses-permission android:name="android.permission.MODIFY_AUDIO_SETTINGS" />

<!-- For Android 10+ internal audio capture -->
<uses-permission android:name="android.permission.CAPTURE_AUDIO_OUTPUT" 
                 android:protectionLevel="signature|privileged" />
```

### Handle Audio Focus Properly

```java
// Request focus that won't pause music
AudioFocusRequest request = new AudioFocusRequest.Builder(
    AudioManager.AUDIOFOCUS_GAIN_TRANSIENT_MAY_DUCK
)
.setAcceptsDelayedFocusGain(true)
.setWillPauseWhenDucked(false)
.build();

audioManager.requestAudioFocus(request);
```

### Prevent Screen Lock

```typescript
import { KeepAwake } from '@capacitor-community/keep-awake';

// Before recognition
await KeepAwake.keepAwake();

// After recognition
await KeepAwake.allowSleep();
```

---

## üîß Debug Tools

Add logging to understand audio routing:

```typescript
async function debugAudioRouting() {
  const devices = await navigator.mediaDevices.enumerateDevices();
  
  console.log('[Audio Debug] Available devices:');
  devices.forEach(device => {
    console.log(`- ${device.kind}: ${device.label}`);
  });
  
  console.log('[Audio Debug] Current constraints:', {
    echoCancellation: false,
    noiseSuppression: false,
    autoGainControl: false
  });
}
```

---

## üí° Pro Tips

1. **Test with actual music** playing from Spotify/YouTube
2. **Test with Bluetooth headphones** connected
3. **Show clear instructions** to user before recognition
4. **Add volume check** - warn if music too quiet
5. **Cache recognized songs** to avoid re-recognition
6. **Implement offline mode** with local song database

---

## üéµ Best Recognition Services (Ranked)

1. **ACRCloud** - Best accuracy, fastest (2-3s), $)
2. **Shazam API** - Good accuracy, fast, $$
3. **AudD** - Decent, slower (5-7s), $
4. **Gracenote** - Good for licensed use, $$$

---

## ‚úÖ Success Metrics

**After implementation:**
- ‚úÖ Recognition success rate: >85%
- ‚úÖ Music playback uninterrupted
- ‚úÖ Bluetooth stays connected
- ‚úÖ Recognition time: <5 seconds
- ‚úÖ Works in background

---

**This will make your recognition as reliable as Shazam!** üéµ‚ú®